/**
 * Moderator Agent
 * 
 * Orchestrates the debate, identifies consensus/conflicts, and synthesizes final recommendation.
 */

import { openrouter } from '@/lib/openrouter';
import type {
    AgentMessage,
    ConsensusItem,
    ConflictItem,
    FinalRecommendation,
    DebateRound,
    AGENT_CONFIGS,
} from './types';

const MODERATOR_MODEL = 'anthropic/claude-sonnet-4';

/**
 * Moderator class
 */
export class Moderator {
    private verbose: boolean;

    constructor(verbose = false) {
        this.verbose = verbose;
    }

    /**
     * Set agenda for Round 0
     */
    async setAgenda(topic: string, context: string): Promise<string> {
        if (this.verbose) {
            console.log('\nüé© Moderador: Definindo agenda...');
        }

        const prompt = `Tu √©s o Moderador de um conselho de IA com 4 agentes especializados.

T√ìPICO: ${topic}

CONTEXTO:
${context}

A tua tarefa √© definir a AGENDA do debate. Os 4 agentes s√£o:
- üîµ Estratega Comercial: Foco em pricing e modelo de neg√≥cio
- üü¢ Advogado do Cliente: Foco na perspetiva do cliente
- üü† T√©cnico/Product: Foco no esfor√ßo e valor t√©cnico
- üî¥ Devil's Advocate: Foco em riscos e obje√ß√µes

Estrutura a agenda em 3 pontos principais que devem ser debatidos.
S√™ conciso e direto. M√°ximo 200 palavras.`;

        const response = await this.callLLM(prompt);
        return response;
    }

    /**
     * Analyze a completed round
     */
    async analyzeRound(
        round: DebateRound,
        previousConsensus: ConsensusItem[],
        previousConflicts: ConflictItem[]
    ): Promise<{ notes: string; consensus: ConsensusItem[]; conflicts: ConflictItem[] }> {
        if (this.verbose) {
            console.log(`\nüé© Moderador: Analisando Round ${round.roundNumber}...`);
        }

        const messagesText = round.messages
            .map(m => `## ${m.agentId.toUpperCase()}\n${m.content}`)
            .join('\n\n');

        const prompt = `Analisa as posi√ß√µes do Round ${round.roundNumber}.

MENSAGENS DOS AGENTES:
${messagesText}

CONSENSO PR√âVIO:
${previousConsensus.length > 0 ? JSON.stringify(previousConsensus, null, 2) : 'Nenhum ainda'}

CONFLITOS PR√âVIOS:
${previousConflicts.length > 0 ? JSON.stringify(previousConflicts, null, 2) : 'Nenhum ainda'}

A TUA TAREFA:
1. Identifica pontos de CONSENSO (onde 3+ agentes concordam)
2. Identifica CONFLITOS (onde h√° discord√¢ncia significativa)
3. Resume as notas do round

Responde em JSON:
{
  "notes": "Resumo do round em 2-3 frases",
  "consensus": [{ "topic": "...", "position": "...", "supportingAgents": ["estratega", "advogado"], "confidence": 0.8 }],
  "conflicts": [{ "topic": "...", "positions": [{ "agentId": "estratega", "position": "..." }], "severity": "MEDIUM" }]
}`;

        const response = await this.callLLM(prompt);

        try {
            const jsonMatch = response.match(/\{[\s\S]*\}/);
            if (jsonMatch) {
                const parsed = JSON.parse(jsonMatch[0]);
                return {
                    notes: parsed.notes || 'An√°lise completa.',
                    consensus: parsed.consensus || [],
                    conflicts: parsed.conflicts || [],
                };
            }
        } catch {
            // Fallback
        }

        return {
            notes: response.slice(0, 200),
            consensus: previousConsensus,
            conflicts: previousConflicts,
        };
    }

    /**
     * Generate final synthesis and recommendation
     */
    async synthesize(
        topic: string,
        rounds: DebateRound[],
        consensus: ConsensusItem[],
        conflicts: ConflictItem[]
    ): Promise<FinalRecommendation> {
        if (this.verbose) {
            console.log('\nüé© Moderador: Sintetizando recomenda√ß√£o final...');
        }

        // Collect all messages for analysis
        const allMessages = rounds.flatMap(r => r.messages);
        const byAgent: Record<string, AgentMessage[]> = {};

        for (const msg of allMessages) {
            if (!byAgent[msg.agentId]) byAgent[msg.agentId] = [];
            byAgent[msg.agentId].push(msg);
        }

        const agentSummaries = Object.entries(byAgent)
            .map(([id, msgs]) => `## ${id.toUpperCase()}\n${msgs.map(m => m.content).join('\n---\n')}`)
            .join('\n\n');

        const prompt = `Tu √©s o Moderador. O debate terminou. Produz a RECOMENDA√á√ÉO FINAL.

T√ìPICO: ${topic}

POSI√á√ïES FINAIS DOS AGENTES:
${agentSummaries}

PONTOS DE CONSENSO:
${JSON.stringify(consensus, null, 2)}

PONTOS DE CONFLITO:
${JSON.stringify(conflicts, null, 2)}

A TUA TAREFA:
Produz uma recomenda√ß√£o unificada que:
1. Resolve os conflitos (escolhendo a melhor posi√ß√£o)
2. Incorpora os pontos de consenso
3. √â acion√°vel e espec√≠fica

Responde em JSON seguindo este schema:
{
  "pricing": {
    "recommended": 7760,
    "minimum": 4160,
    "maximum": 10000,
    "currency": "EUR",
    "justification": "..."
  },
  "strategy": {
    "approach": "One More Thing com upgrade opcional",
    "keyPoints": ["...", "..."],
    "risks": ["...", "..."],
    "mitigations": ["...", "..."]
  },
  "nextSteps": ["Agendar reuni√£o", "Preparar demo", "..."],
  "unanimousPoints": ["Todos concordam que...", "..."],
  "minorityOpinions": [{ "agentId": "devils", "opinion": "..." }]
}`;

        const response = await this.callLLM(prompt);

        try {
            const jsonMatch = response.match(/\{[\s\S]*\}/);
            if (jsonMatch) {
                return JSON.parse(jsonMatch[0]) as FinalRecommendation;
            }
        } catch {
            // Fallback
        }

        // Default fallback recommendation
        return {
            pricing: {
                recommended: 7760,
                minimum: 4160,
                maximum: 10000,
                currency: 'EUR',
                justification: 'Valor baseado no cen√°rio 2 (upgrade platform)',
            },
            strategy: {
                approach: 'One More Thing',
                keyPoints: ['Apresentar scope original como cumprido', 'Revelar plataforma completa'],
                risks: ['Cliente pode recusar upgrade'],
                mitigations: ['Oferecer op√ß√£o de manter pre√ßo original'],
            },
            nextSteps: ['Preparar demo', 'Agendar reuni√£o'],
            unanimousPoints: ['Over-delivery cria goodwill'],
            minorityOpinions: [],
        };
    }

    /**
     * Call LLM
     */
    private async callLLM(prompt: string): Promise<string> {
        if (!openrouter) {
            throw new Error('OpenRouter not configured');
        }

        try {
            const completion = await openrouter.chat.completions.create({
                model: MODERATOR_MODEL,
                messages: [{ role: 'user', content: prompt }],
                max_tokens: 2000,
                temperature: 0.5, // Lower temp for more consistent moderation
            });

            return completion.choices[0]?.message?.content || '';
        } catch (error: any) {
            console.error('‚ùå Moderator LLM call failed:', error.message);
            return '';
        }
    }
}
